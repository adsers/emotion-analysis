# Expression Analysis of Industry Leaders using CNNs
Watch the video below:

[![Watch the video](https://drive.google.com/u/0/uc?id=1iiKGCRsp_a_mrTeJeiaGFO7ZswcdOQAC&export=download)](https://youtu.be/6lsaLdyPeK4)

Facial Expression Recognition is the task of classifying the expressions on face images into various classes such as anger, fear, surprise, sadness, happiness and so on.
Our model has been created to classify expressions into 6  categories, namely: Anger, Fear, Happiness, Neutral, Sadness and Surprise.

#

The aim of this project is to:

1) Build a CNN model from scratch using TensorFlow and a transfer learning model with base as VGGFace to perform Facial Expression Recognition.
2) Collect metadata of the Top-20 TED Talk videos (as sorted by views) in the categories STEM, Global Issues and Entertainment by performing web scraping.
3) Fetch the required TED Talk videos and collect image data using OpenCV.
4) Perform expression analysis on the image data collected in order to gain insights.

The datasets used for building the CNN model from scratch and transfer learning VGGFace model are: FER-2013 and CK+. The idea here is to apply the model trained on the aforementioned sets to the images generated by capturing stills from the **Top 20 TED Talks** from three categories: **STEM, Global Issues and Entertainment.**

#

How to run the project:
1. Fork the repository to local machine
2. Install Python 3.10 and install all additional dependencies in `requirements.txt` using the command `pip install -r ./requirements.txt`.
3. Run the Jupyter notebook from the terminal using the command `python -m jupyterlab`.
